{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g8ypWceVXEKS"
   },
   "source": [
    "# Lab 6 - Sarcasm Detection in Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9nXrahUpq70L"
   },
   "source": [
    "## Overview\n",
    "In this lab, we are going to look into the practical part of figurative language processing. We will employ what we already learnt in the lecture and in previous labs and build on top of that to implement a computational model for sarcasm detection. We are going to employ the SEMEVAL 2016 dataset (https://aclanthology.org/2022.semeval-1.111/). We will focus on:\n",
    "\n",
    "* Data loading and preprocessing\n",
    "* Data analysis\n",
    "* Model development using machine learning and neural networks\n",
    "* Model Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTDJHPUc1Wvh"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "The English training dataset consists of around 4,335 tweets that are divided into sarcastic and non-sarcastic tweets annotated mannually by human annotators (English native speakers).\n",
    "The data can be downloaded from this link: https://sites.google.com/view/semeval2022-isarcasmeval#h.t53li2ejhrh8\n",
    "\n",
    "More information about the dataset prepration can be found in the paper: https://aclanthology.org/2022.semeval-1.111.pdf\n",
    "\n",
    "**Disclaimer:** Since this is a sarcastic content you might find some offensive or rude tweets. The lecturers and TAs assume no responsiblity for such content.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vG1Hj9XF1dI3"
   },
   "source": [
    "## Exercise 1: Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nHI0mMQiFVXA",
    "outputId": "53b6df23-5560-4fab-bf79-1bbca77d8ba3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-23 20:09:16--  https://raw.githubusercontent.com/iabufarha/iSarcasmEval/main/train/train.En.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 491395 (480K) [text/plain]\n",
      "Saving to: ‘train.En.csv’\n",
      "\n",
      "train.En.csv        100%[===================>] 479.88K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2023-02-23 20:09:16 (11.7 MB/s) - ‘train.En.csv’ saved [491395/491395]\n",
      "\n",
      "--2023-02-23 20:09:17--  https://raw.githubusercontent.com/iabufarha/iSarcasmEval/main/test/task_A_En_test.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 130890 (128K) [text/plain]\n",
      "Saving to: ‘task_A_En_test.csv’\n",
      "\n",
      "task_A_En_test.csv  100%[===================>] 127.82K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2023-02-23 20:09:17 (5.14 MB/s) - ‘task_A_En_test.csv’ saved [130890/130890]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download dataset (train and test sets)\n",
    "\n",
    "!wget https://raw.githubusercontent.com/iabufarha/iSarcasmEval/main/train/train.En.csv\n",
    "!wget https://raw.githubusercontent.com/iabufarha/iSarcasmEval/main/test/task_A_En_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjzcInHTHcUA",
    "outputId": "4ffc557c-ed80-4712-fd90-817113390839"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  task_A_En_test.csv  train.En.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SuHTiEaqTajk"
   },
   "source": [
    "\n",
    "**EX 1.1:** Load the dataset from the CSV file and select the tweet id, tweet and the label. In this dataset it is the first 3 columns named \"_,tweet,sarcastic\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 686
    },
    "id": "NmNc3KmtHthK",
    "outputId": "511d28d4-e787-40ed-ed2a-05b175d5c252"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-fd0f731e-3150-446c-8628-6ab8007f91d5\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>rephrase</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>irony</th>\n",
       "      <th>satire</th>\n",
       "      <th>understatement</th>\n",
       "      <th>overstatement</th>\n",
       "      <th>rhetorical_question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>College is really difficult, expensive, tiring...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I do not like when professors don’t write out ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>I, at the bare minimum, wish companies actuall...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>Today my pop-pop told me I was not \"forced\" to...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>I would say Ted Cruz is an asshole and doesn’t...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd0f731e-3150-446c-8628-6ab8007f91d5')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-fd0f731e-3150-446c-8628-6ab8007f91d5 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-fd0f731e-3150-446c-8628-6ab8007f91d5');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  sarcastic  \\\n",
       "0           0  The only thing I got from college is a caffein...          1   \n",
       "1           1  I love it when professors draw a big question ...          1   \n",
       "2           2  Remember the hundred emails from companies whe...          1   \n",
       "3           3  Today my pop-pop told me I was not “forced” to...          1   \n",
       "4           4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
       "\n",
       "                                            rephrase  sarcasm  irony  satire  \\\n",
       "0  College is really difficult, expensive, tiring...      0.0    1.0     0.0   \n",
       "1  I do not like when professors don’t write out ...      1.0    0.0     0.0   \n",
       "2  I, at the bare minimum, wish companies actuall...      0.0    1.0     0.0   \n",
       "3  Today my pop-pop told me I was not \"forced\" to...      1.0    0.0     0.0   \n",
       "4  I would say Ted Cruz is an asshole and doesn’t...      1.0    0.0     0.0   \n",
       "\n",
       "   understatement  overstatement  rhetorical_question  \n",
       "0             0.0            0.0                  0.0  \n",
       "1             0.0            0.0                  0.0  \n",
       "2             0.0            0.0                  0.0  \n",
       "3             0.0            0.0                  0.0  \n",
       "4             0.0            0.0                  0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read train dataset\n",
    "import pandas as pd\n",
    "df_train = pd.read_csv('train.En.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "MvQM39d-K-3B",
    "outputId": "f17ec90b-4e3e-4b14-f9e5-30b07ad86072"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-10472b17-2b34-47d4-94b5-b002720444f0\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10472b17-2b34-47d4-94b5-b002720444f0')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-10472b17-2b34-47d4-94b5-b002720444f0 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-10472b17-2b34-47d4-94b5-b002720444f0');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  sarcastic\n",
       "0           0  The only thing I got from college is a caffein...          1\n",
       "1           1  I love it when professors draw a big question ...          1\n",
       "2           2  Remember the hundred emails from companies whe...          1\n",
       "3           3  Today my pop-pop told me I was not “forced” to...          1\n",
       "4           4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep the first three columns (id, tweet and sarcastic) and drop others\n",
    "df_train = df_train.drop(df_train.columns[3:], axis=1)\n",
    "\n",
    "# Remove empty rows ('nan' value)\n",
    "df_train = df_train.dropna()\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "8_DfcAsbKixW",
    "outputId": "c2906667-980e-406a-cf94-6c8ca0dcccec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-87f013a0-98fb-4bc1-9068-e008a9b2c2e6\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Size on the the Toulouse team, That pack is mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pinball!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So the Scottish Government want people to get ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>villainous pro tip : change the device name on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would date any of these men 🥺</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87f013a0-98fb-4bc1-9068-e008a9b2c2e6')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-87f013a0-98fb-4bc1-9068-e008a9b2c2e6 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-87f013a0-98fb-4bc1-9068-e008a9b2c2e6');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                text  sarcastic\n",
       "0  Size on the the Toulouse team, That pack is mo...          0\n",
       "1                                           Pinball!          0\n",
       "2  So the Scottish Government want people to get ...          1\n",
       "3  villainous pro tip : change the device name on...          0\n",
       "4                    I would date any of these men 🥺          0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('task_A_En_test.csv')\n",
    "df_test = df_test.dropna()\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K24ZmphMPfqF"
   },
   "source": [
    "**Ex 1.2:** Pre-process the text as follows: convert hashtags to text, remove usernames, remove urls, convert emojis into textual descriptions. What other pre-processing steps can be implemented? Speculate how they will affect the model performance. \n",
    "\n",
    "For this exercise, we use *re* library to use regular expression. A regular expression specifies a set of strings that matches it.\n",
    "You can use this [link](https://regexr.com/) to find your regular experssion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6YbaTfWVPkcz"
   },
   "outputs": [],
   "source": [
    "!pip install emoji >> NULL\n",
    "import emoji\n",
    "import re\n",
    "\n",
    "# https://regexr.com/\n",
    "\n",
    "# lowercase\n",
    "def lowercase(text):\n",
    "  return text.lower()\n",
    "\n",
    "# Convert hashtages to text\n",
    "def convert_hashtage(text):\n",
    "  return re.sub(r'#','',text)\n",
    "\n",
    "# Remove usernames\n",
    "def remove_username(text):\n",
    "  return re.sub(r'@\\S+','',text)\n",
    "\n",
    "# Remove URLs\n",
    "def remove_url(text):\n",
    "  return re.sub(r'https?:\\/\\/\\S+', '', text)\n",
    "\n",
    "# Convert emojies\n",
    "def convert_emoji(text):\n",
    "  return emoji.demojize(text)\n",
    "\n",
    "def text_preprocessing_pipeline(text):\n",
    "  text = lowercase(text)\n",
    "  text = convert_hashtage(text)\n",
    "  text = remove_username(text)\n",
    "  text = remove_url(text)\n",
    "  text = convert_emoji(text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "K3rmQ4VcYDep",
    "outputId": "1ec157fc-d9a0-4eca-b4a8-a12914703aa0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6aa447d4-3f52-4e5f-b958-9083a607b096\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>the only thing i got from college is a caffein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>i love it when professors draw a big question ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>remember the hundred emails from companies whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>today my pop-pop told me i was not “forced” to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>i did too, and i also reported cancun cruz ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6aa447d4-3f52-4e5f-b958-9083a607b096')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6aa447d4-3f52-4e5f-b958-9083a607b096 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6aa447d4-3f52-4e5f-b958-9083a607b096');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  sarcastic  \\\n",
       "0           0  The only thing I got from college is a caffein...          1   \n",
       "1           1  I love it when professors draw a big question ...          1   \n",
       "2           2  Remember the hundred emails from companies whe...          1   \n",
       "3           3  Today my pop-pop told me I was not “forced” to...          1   \n",
       "4           4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  the only thing i got from college is a caffein...  \n",
       "1  i love it when professors draw a big question ...  \n",
       "2  remember the hundred emails from companies whe...  \n",
       "3  today my pop-pop told me i was not “forced” to...  \n",
       "4     i did too, and i also reported cancun cruz ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['clean_tweet'] = df_train['tweet'].apply(text_preprocessing_pipeline)\n",
    "df_test['clean_tweet'] = df_test[\"text\"].apply(text_preprocessing_pipeline)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhnhverS1hvN"
   },
   "source": [
    "## Exercise 2: Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQ06mfr2VIAK"
   },
   "source": [
    "\n",
    "**Ex 2.1:** Analyse the sarcastic to non-sarcastic words by:\n",
    "\n",
    "* splitting the dataset using the gold labels into sets of sarcastic and non-sarcastic sentences;\n",
    "* generate the most frequent 25 Noun Phrases for each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C-LJ1StPDpcY",
    "outputId": "7efcd341-7eb7-4e24-ff6e-d2b3e5a5afa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"i always think going braless is a good idea until i'm in public and am insecure because i'm not wearing a bra\", 'life is so much better with a heating blanket', 'sometimes i just go through my phone and look at pictures of my dog', 'was not back in the states for even 5 minutes before someone ran into me at the airport with their suitcase and said “ope, sorry!” \\n\\ni’m home :-)', 'in desperate need of (and i can not stress this enough) spring break', \"i've said it before and i'll say it again but your mental health is so much more important than a good grade\", 'i couldn’t have imagined how much fun i would have with people i’ve met through streaming. i’m so thankful to live in this timeline even if it is relatively garbage.', 'woke up to my dog sneezing on my face. how’s your day going so far?', 'does the salad offset the beer(s)?', 'why do i have a doctorate and miss the restaurant industry so much']\n",
      "['the only thing i got from college is a caffeine addiction', 'i love it when professors draw a big question mark next to my answer on an exam because i’m always like yeah i don’t either ¯\\\\_(ツ)_/¯', 'remember the hundred emails from companies when covid started getting real? i’ve gotten three in regards to support for protests. and only  shared helpful links and actually said black lives matter... we love capitalism :smiling_face_with_hearts::raising_hands_medium-light_skin_tone:', 'today my pop-pop told me i was not “forced” to go to college :upside-down_face: okay sure sureeee', '   i did too, and i also reported cancun cruz not worrying about the heartbeats of his constituents without electricity or heat when he fled to mexico.', ' i choose to interpret it as \"xd\": the universal emoticon for laughing at those poor, poor folks in ubisoft\\'s marketing department who have to deal with that branding until the servers quietly shut down 8 months after launch.', \"why would alexa's recipe for yorkshire pudding be a bhaji yorkshire pudding ?? \", 'someone hit me w a horse tranquilizer istg ive been in a pool of sweat for 6 hours and i havent slept im so tired but i love my friend so much and oh my fucking god i cant rn', 'loving season 4 of trump does america. funniest season yet donaldtrump trump maga maga2020', 'holly arnold ??? who imaceleb  mbe nope not sure oh hang on you mean mbe yes that’s her !!!']\n"
     ]
    }
   ],
   "source": [
    "train_sarc = []\n",
    "train_non_sarc = []\n",
    "for index, tweet in enumerate(df_train[\"clean_tweet\"]):\n",
    "  if df_train[\"sarcastic\"][index] == 1:\n",
    "    train_sarc.append(tweet)\n",
    "  else:\n",
    "    train_non_sarc.append(tweet)\n",
    "print(train_non_sarc[:10])\n",
    "print(train_sarc[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9pQpdyfiW9I"
   },
   "source": [
    "In this exercise, we use *spacy* library to extrcat noun phreas from sarcastic and non-sarcastic sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JRg80GgiZJ8A",
    "outputId": "3c2823a1-6dcd-4302-f803-4219b08bcf31"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "dict_noun_sarc = {}\n",
    "\n",
    "for review in nlp.pipe(train_sarc):\n",
    "  chunks = [(chunk.root.text) for chunk in review.noun_chunks if chunk.root.pos_ == 'NOUN']\n",
    "  for term in chunks:\n",
    "    if dict_noun_sarc.get(term) is None:\n",
    "      dict_noun_sarc[term] = 1\n",
    "    else:\n",
    "      dict_noun_sarc[term] +=1\n",
    "dict_noun_sarc = dict(sorted(dict_noun_sarc.items(), key=lambda x:x[1], reverse=True))\n",
    "\n",
    "dict_noun_non_sarc = {}\n",
    "for review in nlp.pipe(train_non_sarc):\n",
    "  chunks = [(chunk.root.text) for chunk in review.noun_chunks if chunk.root.pos_ == 'NOUN']\n",
    "  for term in chunks:\n",
    "    if dict_noun_non_sarc.get(term) is None:\n",
    "      dict_noun_non_sarc[term] = 1\n",
    "    else:\n",
    "      dict_noun_non_sarc[term] +=1\n",
    "dict_noun_non_sarc = dict(sorted(dict_noun_non_sarc.items(), key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E4xFFNY-Z-4g",
    "outputId": "345147df-0bc4-420c-eb3a-1e9cbfd99a1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['people', 'day', 'time', 'life', 'thing', 'man', 'work', 'thanks', 'friends', 'things', 'game', 'season', 'fun', 'money', 'family', 'way', 'love', 'am', 'dog', 'shit', 'year', 'days', 'house', 'school', 'face']\n",
      "['people', 'time', 'life', 'day', 'thing', 'things', 'friends', 'school', 'work', 'year', 'way', 'love', 'years', 'money', 'job', 'person', 'girl', 'man', 'days', 'world', 'one', 'shit', 'phone', 'dog', 'game']\n"
     ]
    }
   ],
   "source": [
    "print(list(dict_noun_sarc.keys())[:25])\n",
    "print(list(dict_noun_non_sarc.keys())[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXPA_J39FCy-"
   },
   "source": [
    "**Ex 2.2:** Do you see any patterns that diffrentiate sarcastic from non-sarcastic language?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzGZ5x03i-wx"
   },
   "source": [
    "**Ex 2.3:** How many sarcastic to non-sarcastic sentences are there in the labelled training data? How will the label distribution affect the ability of the model to predict sarcastic language?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9sntmcpGjAaI",
    "outputId": "a7bb544a-44f7-4dbf-c2a6-826abf2ccb95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sarcastic sentences in the labelled training data: 867\n",
      "Number of non-sarcastic sentences in the labelled training data: 2600\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of sarcastic sentences in the labelled training data:\", len(train_sarc))\n",
    "print(\"Number of non-sarcastic sentences in the labelled training data:\", len(train_non_sarc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1f_dDLER1kQh"
   },
   "source": [
    "## Exercise 3: Classification Model Design\n",
    "\n",
    "We will focus here on sub-task A in SemEval 2016 Task 6 on Sarcasm Detection. We can formulate this as a sentence-level classification task. \n",
    "\n",
    "**Ex 3.1:** Implement two different ML-based classifiers (Random Forest, SVM) to classify a given sentence to sarcastic or non-sarcastic using the training data. Generate and save predictions on the test set for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "_AbRH3Gtnh4j",
    "outputId": "f0aa5372-dcd4-4013-ccf5-8a800c1d1e3b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0a867f79-4ae1-463a-b61a-2f79866c402d\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>the only thing i got from college is a caffein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>i love it when professors draw a big question ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>remember the hundred emails from companies whe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>today my pop-pop told me i was not “forced” to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>i did too, and i also reported cancun cruz ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>3463</td>\n",
       "      <td>The population spike in Chicago in 9 months is...</td>\n",
       "      <td>0</td>\n",
       "      <td>the population spike in chicago in 9 months is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>3464</td>\n",
       "      <td>You'd think in the second to last English clas...</td>\n",
       "      <td>0</td>\n",
       "      <td>you'd think in the second to last english clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>3465</td>\n",
       "      <td>I’m finally surfacing after a holiday to Scotl...</td>\n",
       "      <td>0</td>\n",
       "      <td>i’m finally surfacing after a holiday to scotl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>3466</td>\n",
       "      <td>Couldn't be prouder today. Well done to every ...</td>\n",
       "      <td>0</td>\n",
       "      <td>couldn't be prouder today. well done to every ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>3467</td>\n",
       "      <td>Overheard as my 13 year old games with a frien...</td>\n",
       "      <td>0</td>\n",
       "      <td>overheard as my 13 year old games with a frien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3467 rows × 4 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a867f79-4ae1-463a-b61a-2f79866c402d')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0a867f79-4ae1-463a-b61a-2f79866c402d button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0a867f79-4ae1-463a-b61a-2f79866c402d');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      Unnamed: 0                                              tweet  \\\n",
       "0              0  The only thing I got from college is a caffein...   \n",
       "1              1  I love it when professors draw a big question ...   \n",
       "2              2  Remember the hundred emails from companies whe...   \n",
       "3              3  Today my pop-pop told me I was not “forced” to...   \n",
       "4              4  @VolphanCarol @littlewhitty @mysticalmanatee I...   \n",
       "...          ...                                                ...   \n",
       "3462        3463  The population spike in Chicago in 9 months is...   \n",
       "3463        3464  You'd think in the second to last English clas...   \n",
       "3464        3465  I’m finally surfacing after a holiday to Scotl...   \n",
       "3465        3466  Couldn't be prouder today. Well done to every ...   \n",
       "3466        3467  Overheard as my 13 year old games with a frien...   \n",
       "\n",
       "      sarcastic                                        clean_tweet  \n",
       "0             1  the only thing i got from college is a caffein...  \n",
       "1             1  i love it when professors draw a big question ...  \n",
       "2             1  remember the hundred emails from companies whe...  \n",
       "3             1  today my pop-pop told me i was not “forced” to...  \n",
       "4             1     i did too, and i also reported cancun cruz ...  \n",
       "...         ...                                                ...  \n",
       "3462          0  the population spike in chicago in 9 months is...  \n",
       "3463          0  you'd think in the second to last english clas...  \n",
       "3464          0  i’m finally surfacing after a holiday to scotl...  \n",
       "3465          0  couldn't be prouder today. well done to every ...  \n",
       "3466          0  overheard as my 13 year old games with a frien...  \n",
       "\n",
       "[3467 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "SkZE8TSvo0MF",
    "outputId": "b6fdf739-54f0-46d8-f7cd-57b29c7892ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-398958ee-6cfd-40de-ac2a-baa01c490320\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Size on the the Toulouse team, That pack is mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pinball!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So the Scottish Government want people to get ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>villainous pro tip : change the device name on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I would date any of these men 🥺</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>I’ve just seen this and felt it deserved a Ret...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>Omg how an earth is that a pen !!! 🤡</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>Bringing Kanye and drake to a tl near you</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>I love it when women are referred to as \"girl ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>The fact that people still don't get that you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-398958ee-6cfd-40de-ac2a-baa01c490320')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-398958ee-6cfd-40de-ac2a-baa01c490320 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-398958ee-6cfd-40de-ac2a-baa01c490320');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                   text  sarcastic\n",
       "0     Size on the the Toulouse team, That pack is mo...          0\n",
       "1                                              Pinball!          0\n",
       "2     So the Scottish Government want people to get ...          1\n",
       "3     villainous pro tip : change the device name on...          0\n",
       "4                       I would date any of these men 🥺          0\n",
       "...                                                 ...        ...\n",
       "1395  I’ve just seen this and felt it deserved a Ret...          0\n",
       "1396               Omg how an earth is that a pen !!! 🤡          0\n",
       "1397          Bringing Kanye and drake to a tl near you          0\n",
       "1398  I love it when women are referred to as \"girl ...          1\n",
       "1399  The fact that people still don't get that you ...          1\n",
       "\n",
       "[1400 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efU7ODOpkjlk"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "tfidf_vectorizer.fit(df_train[\"clean_tweet\"])\n",
    "\n",
    "Xtrain_tfidf = tfidf_vectorizer.transform(df_train[\"clean_tweet\"])\n",
    "Xtest_tfidf = tfidf_vectorizer.transform(df_test[\"text\"])\n",
    "\n",
    "# category class\n",
    "ytrain_label = df_train[\"sarcastic\"].tolist()\n",
    "ytest_label = df_test[\"sarcastic\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoxAaLPFBgA7"
   },
   "source": [
    "Train **Random Forest Classifier** on train dataset and predict labels for test dataset. Finally report precission, recall and f1-score for the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZPY32CJpxsX",
    "outputId": "05498f42-b0f4-4adc-81b3-210b285886cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-sarcastic       0.86      0.97      0.91      1200\n",
      "    sarcastic       0.22      0.06      0.09       200\n",
      "\n",
      "     accuracy                           0.84      1400\n",
      "    macro avg       0.54      0.51      0.50      1400\n",
      " weighted avg       0.77      0.84      0.79      1400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "rfc.fit(Xtrain_tfidf, ytrain_label)\n",
    "ytest_label_pred = rfc.predict(Xtest_tfidf)\n",
    "print(classification_report(ytest_label, ytest_label_pred, zero_division=0, target_names=[\"non-sarcastic\", \"sarcastic\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reofWcYiBnCT"
   },
   "source": [
    "Train **SVM Classifier** on train dataset and predict labels for test dataset. Finally report precission, recall and f1-score for the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "60TsyhD8_wnf",
    "outputId": "4840ff33-dee2-4d6c-d9b5-30099c90f4c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-sarcastic       0.86      1.00      0.92      1200\n",
      "    sarcastic       0.00      0.00      0.00       200\n",
      "\n",
      "     accuracy                           0.86      1400\n",
      "    macro avg       0.43      0.50      0.46      1400\n",
      " weighted avg       0.73      0.86      0.79      1400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm = svm.SVC()\n",
    "svm.fit(Xtrain_tfidf, ytrain_label)\n",
    "ytest_label_pred = svm.predict(Xtest_tfidf)\n",
    "print(classification_report(ytest_label, ytest_label_pred, zero_division=0, target_names=[\"non-sarcastic\", \"sarcastic\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89MiqtXKyjsp"
   },
   "source": [
    "**Oversampling for Imbalanced Dataset**\n",
    "\n",
    "Imbalanced dataset is a dataset with skewed class proportion. In imbalanced dataset, we have a class with a large proportion (majority classes) and a class with a smaller proportion (minority classes). One solution for this challange is [SMOTE (Synthetic Minority Over-sampling Technique)](https://arxiv.org/abs/1106.1813). The idea of SMOTE is to generate synthetic samples by randomly sampling in the minority class.\n",
    "\n",
    "For this exercise, we use\n",
    "[RandomOverSampler](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.RandomOverSampler.html) library for oversampling minority class (sarcastic class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RoMIlHBSzBIx",
    "outputId": "c77c0869-7a36-4765-c3ce-8e547c83325f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 867, 0: 2600})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(ytrain_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7trA_zgAxaN8",
    "outputId": "96745c02-213f-400c-e871-2f5a3c41fe8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 2600, 0: 2600})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "Xtrain_ros, ytrain_ros = ros.fit_resample(Xtrain_tfidf, ytrain_label)\n",
    "Counter(ytrain_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V3wuCum_ze9l",
    "outputId": "67a0980f-02f2-4b4f-bb22-b379c190f3ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-sarcastic       0.88      0.92      0.90      1200\n",
      "    sarcastic       0.32      0.22      0.26       200\n",
      "\n",
      "     accuracy                           0.82      1400\n",
      "    macro avg       0.60      0.57      0.58      1400\n",
      " weighted avg       0.80      0.82      0.81      1400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(Xtrain_ros, ytrain_ros)\n",
    "ytest_ros_pred = rfc.predict(Xtest_tfidf)\n",
    "print(classification_report(ytest_label, ytest_ros_pred, zero_division=0, target_names=[\"non-sarcastic\", \"sarcastic\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q-pa7vZGBt-z",
    "outputId": "231be565-7922-48bd-a9e2-9e5fc7077d14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-sarcastic       0.87      0.97      0.92      1200\n",
      "    sarcastic       0.36      0.10      0.16       200\n",
      "\n",
      "     accuracy                           0.85      1400\n",
      "    macro avg       0.61      0.54      0.54      1400\n",
      " weighted avg       0.79      0.85      0.81      1400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm.fit(Xtrain_ros, ytrain_ros)\n",
    "ytest_ros_pred = svm.predict(Xtest_tfidf)\n",
    "print(classification_report(ytest_label, ytest_ros_pred, zero_division=0, target_names=[\"non-sarcastic\", \"sarcastic\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRs9DClBkiKy"
   },
   "source": [
    "**Ex 3.2** Construct a simple deep neural network-based classifier using (context independent) GloVe word embeddings pretrained on Tweets (https://nlp.stanford.edu/data/glove.twitter.27B.zip). The model architecture should consist of a Bi-LSTM layer and a multi-layer perceptron layer for classification with ReLU activation for the hidden layers and a sigmoid for the output layer.\n",
    "\n",
    "**Ex 3.2.1: Extracting Glove Embeddings** We want to convert our To get started first we'll first install the [Gensim library](https://radimrehurek.com/gensim/auto_examples/index.html#documentation) which provides a set of APIs handling pretrained GloVe models. After install we can load the GloVE Twitter model using the `api.load` from gensim. A full list of supported models can be found here: https://github.com/RaRe-Technologies/gensim-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7-9BdIC2rY2H"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade gensim >> NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NGMCgQwVqgRv"
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "glove = api.load(\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYdp3y2Bz-zA"
   },
   "source": [
    "We can retrieve the specific global word embedding for a given word as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHIGBg1Au7d4",
    "outputId": "0845ae23-d0a6-4e52-a2ce-bb1b9e806a84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.044072, -0.19031 ,  0.44185 , -0.15418 , -0.6026  ,  0.04668 ,\n",
       "        1.4741  ,  0.14376 , -0.72328 ,  0.43288 , -1.7557  ,  0.41221 ,\n",
       "       -4.0419  ,  0.40469 , -0.17825 ,  0.83272 ,  0.64866 ,  0.12397 ,\n",
       "       -0.17873 , -0.59851 ,  0.67779 ,  1.0177  , -0.31664 ,  0.18662 ,\n",
       "       -0.17645 ], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove[\"sad\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0n3wGy70W0j"
   },
   "source": [
    "However trying not all words are present in the GloVe vocabulary. If you try to retrieve a vector for out of scope word, you'll get an error. When dealing with out of vocabulary terms, we can either drop them during the feature extraction process or map them all to the `UNK` token. What might be some pros and cons of this these two strategies?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ETNTRDMZ1okw"
   },
   "source": [
    "We'll create `vocab2id` dictionary which will map each word in the word to a numerical value called the token id. Gensim uses the .vocab attribute which is dictionary object containing the mappings of words to pretrained embedding vectors. If we convert the vocabulary keys into a flat list, each index in the list will correspond to a specific word. This will allow us to represent the text as a list of token ids that we can pass to model.\n",
    "\n",
    "Note: As of Gensim 4.0, this functionality is avaialable through `glove.key_to_index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ZheD02a3fJl"
   },
   "outputs": [],
   "source": [
    "vocab2id = glove.key_to_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfEBWCY04ilI"
   },
   "source": [
    "Next we'll encode our text inputs using the token ids which correspond to the GloVe vocabulary. We create a function which takes in a string and returns the encoded token ids using the `vocab2id` mapping. If we run across words not in the vocabulary, we'll drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P43ckKyH6ohw",
    "outputId": "7163f0b2-9648-4566-80d9-f1cfef6cf946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1135, 46, 2034, 4327, 32, 168369]\n"
     ]
    }
   ],
   "source": [
    "from typing import List \n",
    "\n",
    "def encode_text(text: str, vocab2id: dict) -> List[int]:\n",
    "  \"\"\"\n",
    "  Function takes in a text and a vocab to id mapping. Return\n",
    "  back a list of token ids corresponding to each word in the\n",
    "  input text.\n",
    "  \"\"\"\n",
    "  # 1. Tokenize text using white space splitting\n",
    "  toks = text.split()\n",
    "\n",
    "  # 2. Encode text. \n",
    "  encoded_ids = [vocab2id[tok] for tok in toks if tok in vocab2id]\n",
    "  return encoded_ids\n",
    "\n",
    "sample_tweet = \"working on deep learning is greaat\"\n",
    "print(encode_text(sample_tweet, vocab2id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8itFHdSL8RgI"
   },
   "source": [
    "Let go ahead apply this function to the clean_tweet column on both the train and test dataframes. We'll create new column called encoded_text which will contain the ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "PRYD0Jbb4eV9",
    "outputId": "cbd07a58-ac9d-48c6-b2fc-f6a3cad373f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-80383628-ee66-4677-9cce-377da96365c7\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sarcastic</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>encoded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The only thing I got from college is a caffein...</td>\n",
       "      <td>1</td>\n",
       "      <td>the only thing i got from college is a caffein...</td>\n",
       "      <td>[13, 214, 410, 10, 143, 133, 1502, 32, 11, 224...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I love it when professors draw a big question ...</td>\n",
       "      <td>1</td>\n",
       "      <td>i love it when professors draw a big question ...</td>\n",
       "      <td>[10, 68, 33, 92, 42029, 4776, 11, 398, 1411, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember the hundred emails from companies whe...</td>\n",
       "      <td>1</td>\n",
       "      <td>remember the hundred emails from companies whe...</td>\n",
       "      <td>[626, 13, 9759, 14129, 133, 9923, 92, 1302, 39...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Today my pop-pop told me I was not “forced” to...</td>\n",
       "      <td>1</td>\n",
       "      <td>today my pop-pop told me i was not “forced” to...</td>\n",
       "      <td>[148, 29, 677166, 813, 21, 10, 93, 78, 16, 111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@VolphanCarol @littlewhitty @mysticalmanatee I...</td>\n",
       "      <td>1</td>\n",
       "      <td>i did too, and i also reported cancun cruz ...</td>\n",
       "      <td>[10, 195, 26, 10, 894, 12302, 23433, 5965, 78,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80383628-ee66-4677-9cce-377da96365c7')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-80383628-ee66-4677-9cce-377da96365c7 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-80383628-ee66-4677-9cce-377da96365c7');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  sarcastic  \\\n",
       "0           0  The only thing I got from college is a caffein...          1   \n",
       "1           1  I love it when professors draw a big question ...          1   \n",
       "2           2  Remember the hundred emails from companies whe...          1   \n",
       "3           3  Today my pop-pop told me I was not “forced” to...          1   \n",
       "4           4  @VolphanCarol @littlewhitty @mysticalmanatee I...          1   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  the only thing i got from college is a caffein...   \n",
       "1  i love it when professors draw a big question ...   \n",
       "2  remember the hundred emails from companies whe...   \n",
       "3  today my pop-pop told me i was not “forced” to...   \n",
       "4     i did too, and i also reported cancun cruz ...   \n",
       "\n",
       "                                        encoded_text  \n",
       "0  [13, 214, 410, 10, 143, 133, 1502, 32, 11, 224...  \n",
       "1  [10, 68, 33, 92, 42029, 4776, 11, 398, 1411, 2...  \n",
       "2  [626, 13, 9759, 14129, 133, 9923, 92, 1302, 39...  \n",
       "3  [148, 29, 677166, 813, 21, 10, 93, 78, 16, 111...  \n",
       "4  [10, 195, 26, 10, 894, 12302, 23433, 5965, 78,...  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"encoded_text\"] = df_train[\"clean_tweet\"].apply(lambda x: encode_text(x, vocab2id))\n",
    "df_test[\"encoded_text\"] = df_test[\"clean_tweet\"].apply(lambda x: encode_text(x, vocab2id))\n",
    "\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGfZd0e4-Ngh"
   },
   "source": [
    "It's good idea to have a seperate validation set that we can use during training to evaluate how well the model is converging and avoid overfitting. We'll first split a 15% of the `df_train` into a seperate validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOKxGfF786Oz"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(\n",
    "    df_train, \n",
    "    test_size=.15, \n",
    "    stratify = df_train[\"sarcastic\"],\n",
    "    random_state=2023\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xjM9PiWAYQr"
   },
   "source": [
    "Finally we can go create the DataSet and DataLoader that will used to generate the batches for the training. As the sequences are different lengths, we'll need to first standardize them to a fixed length. For sequences that are shorter than the fixed length, we'll right pad the sequence with a paddding token id reach the desire length. For longer sequences we'll truncate all token after past the specified length. We'll use the pytorch method [`pad_sequences`](https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html) which handle this for padding all sequences in a list to the longest sequence length it finds. \n",
    "\n",
    "We'll also need to specify the padding value which tradionally is zero. However our GloVe embeddings already has a word assigned to the zero id. So we'll have to create new pad token and empty embedding and append it to the end of the vocab list and list of vectors. The id for this pad token will `len(vocab)` prior to adding the token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3yrOsdz_sdg",
    "outputId": "5ee0f60b-eae8-4400-ef00-7c2bb9ac85de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2946, 55])\n",
      "torch.Size([521, 49])\n",
      "torch.Size([1400, 117])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "pad_token_id = len(vocab2id)\n",
    "\n",
    "# Train Inputs \n",
    "train_inputs = [torch.LongTensor(encoded_text) for encoded_text in train[\"encoded_text\"].tolist()]\n",
    "train_inputs = pad_sequence(\n",
    "    train_inputs, \n",
    "    batch_first=True, \n",
    "    padding_value = pad_token_id)\n",
    "print(train_inputs.shape)\n",
    "\n",
    "# Val inputs\n",
    "val_inputs = [torch.LongTensor(encoded_text) for encoded_text in val[\"encoded_text\"].tolist()]\n",
    "val_inputs = pad_sequence(\n",
    "    val_inputs, \n",
    "    batch_first=True, \n",
    "    padding_value = pad_token_id)\n",
    "print(val_inputs.shape)\n",
    "\n",
    "# Test inputs\n",
    "test_inputs = [torch.LongTensor(encoded_text) for encoded_text in df_test[\"encoded_text\"].tolist()]\n",
    "test_inputs = pad_sequence(\n",
    "    test_inputs, \n",
    "    batch_first=True, \n",
    "    padding_value = pad_token_id)\n",
    "print(test_inputs.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8s39POxg4deQ"
   },
   "source": [
    "Let's go ahead and create the final DataSet and DataLoader objects for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ITRqsAdGg9SL"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# First extract the labels\n",
    "train_labels = torch.FloatTensor(train[\"sarcastic\"].tolist())\n",
    "val_labels = torch.FloatTensor(val[\"sarcastic\"].tolist())\n",
    "test_labels = torch.FloatTensor(df_test[\"sarcastic\"].tolist())\n",
    "\n",
    "# Data loaders\n",
    "train_dl = DataLoader(\n",
    "    TensorDataset(\n",
    "      train_inputs,\n",
    "      train_labels,   \n",
    "    ),\n",
    "    shuffle=True,\n",
    "    batch_size = 64\n",
    ")\n",
    "\n",
    "val_dl = DataLoader(\n",
    "    TensorDataset(\n",
    "        val_inputs,\n",
    "        val_labels\n",
    "    ),\n",
    "    shuffle=False,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "test_dl = DataLoader(\n",
    "    TensorDataset(\n",
    "        test_inputs,\n",
    "        test_labels\n",
    "    ),\n",
    "    shuffle=False,\n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opeyEBfBqi0U"
   },
   "source": [
    "\n",
    "**Ex 3.2.2: Developing the BiLSTM Classififier**\n",
    "In this section we focus on architecting our classification model. At a high level our model will consit of the following:\n",
    "- Embedding layer consisting of the pretrained GloVe weights\n",
    "- BiLSTM layer: a neural architecture to model the sequential dependencies in text\n",
    "- Classification head: a multi-layer perceptron which maps the hidden representation to our classification space (a binary outcome).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2sj60c3sXy1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import numpy as np\n",
    "\n",
    "class SarcasmClassifier(nn.Module):\n",
    "\n",
    "  def __init__(\n",
    "      self, \n",
    "      glove: torch.FloatTensor,\n",
    "      lstm_input_dim: int = 25,         # Dimension of GloVe embeddings\n",
    "      lstm_hidden_dim: int = 64,  # Hidden dim for LSTM\n",
    "      lstm_num_layers: int = 2,         # Number of LSTM layers\n",
    "    ):\n",
    "    super().__init__()\n",
    "    # Extract GloVe weights and add padding tensor to end\n",
    "    glove_weights = glove.vectors\n",
    "    padding_tensor = np.zeros(lstm_input_dim).reshape(1,-1)\n",
    "    glove_weights = np.concatenate((glove_weights, padding_tensor), axis=0)\n",
    "    glove_weights = torch.FloatTensor(glove_weights)\n",
    "\n",
    "    # Architecture\n",
    "    self.embedding_layer = nn.Embedding.from_pretrained(glove_weights)\n",
    "    self.bilstm_layer = nn.LSTM(\n",
    "        input_size = lstm_input_dim,\n",
    "        hidden_size = lstm_hidden_dim,\n",
    "        num_layers = lstm_num_layers,\n",
    "        bidirectional=True, \n",
    "        batch_first=True\n",
    "    )\n",
    "    self.linear1 = nn.Linear(lstm_hidden_dim * 2, (lstm_hidden_dim * 2) // 4 )\n",
    "    self.linear2 = nn.Linear((lstm_hidden_dim * 2) // 4, 1)\n",
    "\n",
    "  def forward(self, X: torch.tensor) -> torch.tensor:\n",
    "\n",
    "    # 1. Retrieve embedding\n",
    "    embedding = self.embedding_layer(X)\n",
    "    \n",
    "    # Extract last hidden layer from LSTM \n",
    "    lstm_out, (hidden_state, cell_state) = self.bilstm_layer(embedding)\n",
    "    lstm_feats = torch.cat((hidden_state[-1, :, :], hidden_state[-2, :, :]), dim=1)\n",
    "    \n",
    "    # Map lstm hidden representation to output space \n",
    "    l1 = F.relu(F.dropout(self.linear1(lstm_feats), p=.5))\n",
    "    logits = self.linear2(l1)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieSgzp8RqQ9X"
   },
   "source": [
    "\n",
    "**Ex 3.3:** Train this model for 50 epochs. Generate and save the model predictions on the test set. \n",
    "\n",
    "**Ex 3.3.1: Training Preparation**\n",
    "Prior to training, we'll need to do the following\n",
    "- initialize an optimizer \n",
    "- initialize a loss function\n",
    "- freeze the embedding layer weights for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEGR6BjMm7e3"
   },
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "model = SarcasmClassifier(\n",
    "    glove, \n",
    "    lstm_input_dim=25,\n",
    "    lstm_num_layers=2,\n",
    "    lstm_hidden_dim=256,\n",
    "  )\n",
    "\n",
    "# Establish loss criterion\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Freeze embedding layer\n",
    "for name, param in model.named_parameters():\n",
    "  if 'embedding_layer' in name:\n",
    "    param.requires_grad = False \n",
    "\n",
    "# Initialize optimzer w/ model parameters \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClG14ZxRFiEJ"
   },
   "source": [
    "Finally we implement our training loop. At a high level the loop must do the following:\n",
    "- zero out the optimizer gradients\n",
    "- perform a forward pass on the batch inputs\n",
    "- calculate the loss\n",
    "- backprop the loss through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZLEuCZKuwYIh",
    "outputId": "3c96e6fa-6945-462b-e1c1-f04dc9f30a4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train loss 0.129 | Val Loss: 1.258 | Val F1: 0.27118644067796616\n",
      "Epoch 5: Train loss 0.058 | Val Loss: 1.736 | Val F1: 0.2678571428571429\n",
      "Epoch 10: Train loss 0.029 | Val Loss: 1.946 | Val F1: 0.31034482758620696\n",
      "Epoch 15: Train loss 0.008 | Val Loss: 2.306 | Val F1: 0.29694323144104806\n",
      "Epoch 20: Train loss 0.003 | Val Loss: 2.886 | Val F1: 0.31034482758620696\n"
     ]
    }
   ],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "num_epochs = 25\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "  # Set model to train model\n",
    "  model.train()\n",
    "\n",
    "  running_loss_train = 0.0\n",
    "  num_batches_train = 0\n",
    "  \n",
    "  # Iterate over train batches\n",
    "  for batch in train_dl:\n",
    "\n",
    "    inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "    optimizer.zero_grad()           # 1. Zero out the optimizer gradients\n",
    "    logits = model.forward(inputs)  # 2. Forward pass on the model\n",
    " \n",
    "    loss = criterion(logits, labels.view(-1,1)) # 3. Calculate loss\n",
    "    loss.backward()                             # 4. Backprop loss\n",
    "    optimizer.step()                            # 5. Optimizer step\n",
    "\n",
    "    running_loss_train += loss.item()\n",
    "    num_batches_train += 1\n",
    "  train_loss = round(running_loss_train / num_batches_train, 3)\n",
    "  \n",
    "\n",
    "  if epoch % 5 == 0:\n",
    "    # Evaluate Model\n",
    "    model.eval() # Set to eval mode\n",
    "\n",
    "    running_loss_val = 0\n",
    "    num_batches_val = 0\n",
    "    all_preds = []\n",
    "    all_gold  = []\n",
    "    for batch in val_dl:\n",
    "      inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "      logits = model.forward(inputs)  \n",
    "      loss = criterion(logits, labels.view(-1,1)) \n",
    "\n",
    "      running_loss_val += loss.item()\n",
    "      num_batches_val += 1\n",
    "\n",
    "      preds = [round(pred.item()) for pred in torch.sigmoid(logits).view(-1).detach()]\n",
    "      all_preds.extend(preds)\n",
    "      all_gold.extend(labels.tolist())\n",
    "\n",
    "    val_loss = round(running_loss_val / num_batches_val, 3)\n",
    "    val_acc = f1_score(all_gold, all_preds)\n",
    "\n",
    "    print(f\"Epoch {epoch}: Train loss {train_loss} | Val Loss: {val_loss} | Val F1: {val_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uFPdG16z8vL0",
    "outputId": "bae8c733-6883-4503-f956-dfd813f3a85d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.80      0.83      1200\n",
      "         1.0       0.17      0.25      0.20       200\n",
      "\n",
      "    accuracy                           0.72      1400\n",
      "   macro avg       0.52      0.52      0.52      1400\n",
      "weighted avg       0.77      0.72      0.74      1400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_gold  = []\n",
    "for batch in test_dl:\n",
    "  inputs, labels = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "  logits = model.forward(inputs)  \n",
    "  loss = criterion(logits, labels.view(-1,1)) # 3. Calculate loss\n",
    "\n",
    "  running_loss_val += loss.item()\n",
    "  num_batches_val += 1\n",
    "\n",
    "  preds = [round(pred.item()) for pred in torch.sigmoid(logits).view(-1).detach()]\n",
    "  all_preds.extend(preds)\n",
    "  all_gold.extend(labels.tolist())\n",
    "\n",
    "print(classification_report(all_gold, all_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pN9wqRte1oqS"
   },
   "source": [
    "## Exercise 4: Evaluation\n",
    "\n",
    "**Ex 4.1:** What quantitative metrics do you think would be appropriate for evaluating this classification task? and why?\n",
    "\n",
    "**Ex 4.2:** Use the metrics selected in Ex 3.1 to evaluate the predictions of the implemented Ml and DL models of Ex 2. Compare the results from the two different models and determine which one performs the best and why."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
